{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pre_trained = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def distance_canberra_mat(d1, d2):\n",
    "    ### Don't seems to work in scipy    \n",
    "    divide = abs(d1) + abs(d2)    \n",
    "    distance = np.sum(np.divide(abs(d1-d2), divide, where=divide!=0), axis=1)    \n",
    "    return distance\n",
    "    \n",
    "def distance_cosine_mat(d1, d2):\n",
    "    ### Don't seems to work in scipy\n",
    "    val = np.sum(d1*d2, axis=1)\n",
    "    divide = np.sqrt(np.sum((d1*d1), axis=1))*np.sqrt(np.sum((d2*d2), axis=1))\n",
    "    return 1 - np.divide(val, divide)\n",
    "\n",
    "def distance_khi2_mat_w(d1, d2, w):\n",
    "    divide = (d1 + d2)*w    \n",
    "    distance = np.sum(np.divide((d1-d2)**2, divide, where=divide!=0), axis=1)   \n",
    "    return distance\n",
    "\n",
    "def distance_khi2_mat(d1, d2):\n",
    "    divide = d1 + d2    \n",
    "    distance = np.sum(np.divide((d1-d2)**2, divide, where=divide!=0), axis=1)   \n",
    "    return distance\n",
    "\n",
    "\n",
    "def distance_braycurtis_mat(d1, d2):\n",
    "    divide = np.sum(abs(d1 + d2), axis=1)\n",
    "    distance = np.divide(np.sum(abs(d1-d2), axis=1), divide)   \n",
    "    return distance\n",
    "\n",
    "\n",
    "def distance_eucl_mat(d1, d2):\n",
    "    distance = np.sqrt(np.sum((d1-d2)**2, axis=1))   \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = pd.read_csv(\"data/train_with_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_label[[\"QS\",\"QR\"]].to_csv(\"data/train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = None\n",
    "\n",
    "\n",
    "if(pre_trained==False) :\n",
    "    xtrain=pd.read_csv(\"data/xtrain_challenge.csv\")\n",
    "    train_data = xtrain\n",
    "    \n",
    "    cols_qs = list(xtrain.columns)[:13]\n",
    "    cols_qr = list(xtrain.columns)[13:26]\n",
    "    cols_S1_11 = list(xtrain.columns)[26:37]\n",
    "    \n",
    "\n",
    "\n",
    "    # On créé des features artificielles:\n",
    "    # Q1-13 Q13-26 sont des identifiants uniques d'un visage\n",
    "    # On suppose que Q1-13 et Q13-26 pourrait etre inversé\n",
    "    # On regarde si on n'aurait pas des liaisons à faire en plus\n",
    "\n",
    "    # Merge des colonnes\n",
    "\n",
    "    train_data[\"QS\"] = train_data[cols_qs].apply(\n",
    "        lambda x: '_'.join(x.astype(str)),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Merge des colonnes\n",
    "\n",
    "    train_data[\"QR\"] = train_data[cols_qr].apply(\n",
    "        lambda x: '_'.join(x.astype(str)),\n",
    "        axis=1\n",
    "    )\n",
    "    train_data['QS'] = train_data['QS'].apply(lambda x: hash(x))\n",
    "    train_data['QR'] = train_data['QR'].apply(lambda x: hash(x))\n",
    "    train_data[['QS','QR']].to_csv(\"data/train_labels.csv\")\n",
    "else:\n",
    "    train_data = pd.read_csv(\"data/xtrain_challenge.csv\")\n",
    "    \n",
    "  \n",
    "    \n",
    "cols_qs = list(train_data.columns)[:13]\n",
    "cols_qr = list(train_data.columns)[13:26]\n",
    "cols_S1_11 = list(train_data.columns)[26:37]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"canberra\"]=distance_canberra_mat(train_data[cols_qr].values, train_data[cols_qs].values)\n",
    "train_data[\"cosine\"]=distance_cosine_mat(train_data[cols_qr].values, train_data[cols_qs].values)\n",
    "train_data[\"khi2\"]=distance_khi2_mat(train_data[cols_qr].values,train_data[cols_qs].values)\n",
    "train_data[\"braycurtis\"]=distance_braycurtis_mat(train_data[cols_qr].values,train_data[cols_qs].values)\n",
    "train_data[\"euclidian\"]=distance_eucl_mat(train_data[cols_qr].values,train_data[cols_qs].values)\n",
    "ytrain=pd.read_csv(\"data/ytrain_challenge.csv\")\n",
    "xtrain = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['QS'] = train_label['QS']\n",
    "train_data['QR'] = train_label['QR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data[train_data.label==1].groupby(\"QS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in list(xtrain.columns):    \n",
    "    xtrain[c].plot(kind='hist', bins=30)\n",
    "    plt.title(c)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "xtest = pd.read_csv('data/xtest_challenge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest[\"canberra\"]=distance_canberra_mat(xtest[cols_qr].values, xtest[cols_qs].values)\n",
    "xtest[\"cosine\"]=distance_cosine_mat(xtest[cols_qr].values, xtest[cols_qs].values)\n",
    "xtest[\"khi2\"]=distance_khi2_mat(xtest[cols_qr].values,xtest[cols_qs].values)\n",
    "xtest[\"braycurtis\"]=distance_braycurtis_mat(xtest[cols_qr].values,xtest[cols_qs].values)\n",
    "xtest[\"euclidian\"]=distance_eucl_mat(xtest[cols_qr].values,xtest[cols_qs].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va calculer des distances entre les features Q1-13 et Q13-26\n",
    "\n",
    "https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul d'un SVM pour connaitre les coefficients des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.LinearSVC()\n",
    "\n",
    "d1 = train_data[cols_qs].values\n",
    "d2 = train_data[cols_qr].values\n",
    "\n",
    "divide = d1 + d2 \n",
    "X = np.divide((d1-d2)**2, divide, where=divide!=0)\n",
    "\n",
    "X_SVM, X_SVM_test, y_SVM, y_SVM_test = train_test_split(X, ytrain, test_size=0.98) # SVM on 2% of data\n",
    "\n",
    "X_SVM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_SVM, y_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest[\"khi2 W\"]=distance_khi2_mat_w(xtest[cols_qr].values,xtest[cols_qs].values, w)\n",
    "train_data[\"khi2_W\"]=distance_khi2_mat_w(train_data[cols_qr].values,train_data[cols_qs].values,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain[xtrain.qr9 >xtrain.qs9.max()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain[xtrain.qr1 >xtrain.qs1.max()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest[xtest.qr1>1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest[xtest.qr9> xtrain.qs9.max()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_clean = xtrain[xtrain.qr1<=1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_unique = len(xtrain_clean.QS.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for c in list(xtrain_clean.columns):\n",
    "    xtrain_clean[c].plot(kind='hist', bins=30, logy=True)   \n",
    "    plt.title(c)\n",
    "    plt.show()    \n",
    "    xtrain_clean[c].plot(kind='hist', bins=30)\n",
    "    plt.title(c)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xtrain_clean.QR.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_clean = ytrain[xtrain.qr1 <=1]\n",
    "yone = ytrain_clean[ytrain_clean==1]\n",
    "\n",
    "import math\n",
    "\n",
    "choosen = sk.utils.random.sample_without_replacement(qs_unique,qs_unique//8)\n",
    "\n",
    "# get the hash of the data\n",
    "qs = xtrain_clean.QS.iloc[choosen].values\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.in1d(xtrain_clean.QS.values, qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_clean.QS[indices].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(xtrain_clean, ytrain[xtrain.qr1 <=1], test_size=0.33, random_state=42)\n",
    "\n",
    "X_train= xtrain_clean[][~indices]\n",
    "X_test=xtrain_clean[indices]\n",
    "y_train= ytrain_clean[~indices]\n",
    "y_test=ytrain_clean[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_active = list(train_data.columns)\n",
    "\n",
    "remove_list=[\"QS\",\"QR\"] #, \"qs1\",\"qr1\",\"qs2\",\"qr2\",\"qs3\",\"qr3\",\"qs12\",\"qr12\"]    \n",
    "for i in remove_list: \n",
    "    try: \n",
    "        cols_active.remove(i) \n",
    "    except ValueError: \n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import lightgbm \n",
    "# making lgbm datasets for train and valid\n",
    "d_train = lightgbm.Dataset(X_train[cols_active], y_train)\n",
    "d_valid = lightgbm.Dataset(X_test[cols_active], y_test)\n",
    "    \n",
    "parameters = {\n",
    "    'application': 'binary',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_error',\n",
    "    'is_unbalance': 'false',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 100,\n",
    "    'max_bin':1024,\n",
    "    'feature_fraction': 0.3,\n",
    "    'bagging_fraction': 0.2,\n",
    "    'bagging_freq': 5,\n",
    "    'learning_rate': 0.01,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "model = lightgbm.train(parameters,\n",
    "                       d_train,\n",
    "                       valid_sets=d_valid,\n",
    "                       num_boost_round=1000,\n",
    "                       early_stopping_rounds=50)   \n",
    "    # making prediciton for one column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "lightgbm.plot_importance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_model('lgbm_distance.txt')\n",
    "\n",
    "soft = model.predict(X_test)\n",
    "\n",
    "print('Fininshed Training')\n",
    "soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yvalid = soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = np.sum(y_test == 0).values\n",
    "P = np.sum(y_test == 1).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yvalid_scoreordered = y_test.values[np.argsort(yvalid)]\n",
    "\n",
    "\n",
    "FP = 0.0\n",
    "TP = 0.0\n",
    "val = 0\n",
    "print(N)\n",
    "print(P)\n",
    "for i in range(len(y_test) - 1, -1, -1):        \n",
    "    if (yvalid_scoreordered[i] == 1):\n",
    "        TP = TP + 1\n",
    "    else:\n",
    "        FP = FP + 1\n",
    "        #print(X_test[cols].iloc(i))\n",
    "    if (FP / N > 10**-4):\n",
    "        FP = FP - 1\n",
    "        break\n",
    "print(\"For the smallest FPR <= 10^-4 (i.e., \", FP / N, \") TPR = \", TP / P, \".\", sep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "xtest = pd.read_csv('data/xtest_challenge.csv')\n",
    "xtest[\"canberra\"]=distance_canberra_mat(xtest[cols_qr].values, xtest[cols_qs].values)\n",
    "xtest[\"cosine\"]=distance_cosine_mat(xtest[cols_qr].values, xtest[cols_qs].values)\n",
    "xtest[\"khi2\"]=distance_khi2_mat(xtest[cols_qr].values,xtest[cols_qs].values)\n",
    "xtest[\"braycurtis\"]=distance_braycurtis_mat(xtest[cols_qr].values,xtest[cols_qs].values)\n",
    "xtest[\"euclidian\"]=distance_eucl_mat(xtest[cols_qr].values,xtest[cols_qs].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the provided test data\n",
    "ytest = model.predict(xtest.values)\n",
    "print(ytest.shape)\n",
    "np.savetxt('ytest_lbgm_distance_s1.csv', ytest, fmt = '%1.15f', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
